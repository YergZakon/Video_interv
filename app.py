import streamlit as st
import logging # Added
import threading
import time
import numpy as np
import queue
import os
from pathlib import Path
import matplotlib.pyplot as plt
import yaml

from modules.video_analyzer import VideoAnalyzer
from modules.audio_analyzer import AudioAnalyzer
from modules import MultimodalIntegrator
from modules.data_manager import QuestionManager
from utils.visualization import plot_voice_characteristics, plot_multimodal_timeline, create_distortion_summary

# Setup logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # Default level
# Avoid adding multiple handlers if script re-runs (e.g. Streamlit auto-reload)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(module)s:%(lineno)d - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# Attempt to import cv2 and set a flag
cv2_available = False
cv2 = None
try:
    import cv2
    cv2_available = True
    logger.info("OpenCV (cv2) imported successfully.")
except ImportError:
    logger.error("OpenCV (cv2) not found. Video analysis functions will be unavailable.", exc_info=False)
    st.error("OpenCV (cv2) –Ω–µ –Ω–∞–π–¥–µ–Ω. –§—É–Ω–∫—Ü–∏–∏ –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

# Attempt to import pyaudio and set a flag
pyaudio_available = False
pyaudio = None
try:
    import pyaudio
    pyaudio_available = True
    logger.info("PyAudio imported successfully.")
except ImportError:
    logger.error("PyAudio not found. Audio analysis functions will be unavailable.", exc_info=False)
    st.error("PyAudio –Ω–µ –Ω–∞–π–¥–µ–Ω. –§—É–Ω–∫—Ü–∏–∏ –∞—É–¥–∏–æ–∞–Ω–∞–ª–∏–∑–∞ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
frame_queue = queue.Queue(maxsize=5)
audio_queue = queue.Queue(maxsize=5)
stop_event = threading.Event()
session_active = False

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ
def video_capture_thread(video_analyzer, integrator):
    logger.info("Video capture thread initiated.")
    if not cv2_available or video_analyzer is None:
        logger.warning("Video capture thread not starting: cv2 or video_analyzer unavailable.")
        st.warning("–í–∏–¥–µ–æ–∑–∞—Ö–≤–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Ç–∞–∫ –∫–∞–∫ cv2 –∏–ª–∏ video_analyzer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        return

    cap = None
    try:
        logger.info("Attempting to open webcam.")
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            logger.error("Failed to open webcam.")
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É.")
            return
        
        logger.info("Webcam opened successfully.")
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        while not stop_event.is_set():
            ret, frame = cap.read()
            if ret:
                # –ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–∞
                processed_frame = video_analyzer.process_frame(frame)
                
                if not frame_queue.full():
                    frame_queue.put(processed_frame)
                    
                timestamp = time.time()
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä
                video_result = {'frame': processed_frame}
                if integrator:
                    integrator.add_video_result(video_result, timestamp)
                
                time.sleep(0.03)  # ~30 FPS
            else:
                logger.warning("Failed to retrieve frame from webcam. Retrying...")
                time.sleep(0.1) # Wait a bit if reading fails
    except Exception as e:
        logger.exception("Exception in video_capture_thread.")
        st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –≤–∏–¥–µ–æ–∑–∞—Ö–≤–∞—Ç–∞: {e}")
    finally:
        if cap and cap.isOpened():
            cap.release()
            logger.info("Webcam released.")
        logger.info("Video capture thread stopping.")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ
def audio_capture_thread(audio_analyzer, integrator):
    logger.info("Audio capture thread initiated.")
    if not pyaudio_available or audio_analyzer is None:
        logger.warning("Audio capture thread not starting: pyaudio or audio_analyzer unavailable.")
        st.warning("–ê—É–¥–∏–æ–∑–∞—Ö–≤–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, —Ç–∞–∫ –∫–∞–∫ pyaudio –∏–ª–∏ audio_analyzer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        return

    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    
    p = None
    stream = None
    try:
        logger.info("Initializing PyAudio.")
        p = pyaudio.PyAudio()
        logger.info("Attempting to open PyAudio stream.")
        stream = p.open(format=FORMAT,
                        channels=CHANNELS,
                        rate=RATE,
                        input=True,
                        frames_per_buffer=CHUNK)
        logger.info("PyAudio stream opened successfully.")
        st.info("–ê—É–¥–∏–æ–∑–∞—Ö–≤–∞—Ç –Ω–∞—á–∞—Ç.")
        
        while not stop_event.is_set():
            try:
                audio_data = stream.read(CHUNK, exception_on_overflow=False)
                audio_chunk = np.frombuffer(audio_data, dtype=np.int16)
                
                if not audio_queue.full():
                    audio_queue.put(audio_chunk)
                
                if audio_analyzer: # Ensure analyzer exists
                    audio_result = audio_analyzer.process_audio(audio_chunk)
                    if audio_result and integrator: # Ensure integrator exists
                        timestamp = time.time()
                        integrator.add_audio_result(audio_result, timestamp)
            except IOError as e:
                if e.errno == pyaudio.paInputOverflowed: # type: ignore
                    logger.warning("Input audio buffer overflowed.", exc_info=False) # Traceback not very useful here
                    st.warning("–ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞ –∞—É–¥–∏–æ. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –º–æ–≥–ª–∏ –±—ã—Ç—å –ø–æ—Ç–µ—Ä—è–Ω—ã.")
                else:
                    logger.error("IOError reading from audio stream.", exc_info=True)
                    st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞: {e}")
                    break # Exit loop on other IOErrors
            except Exception as e:
                logger.exception("Exception processing audio chunk.")
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}")
                time.sleep(0.1) # Avoid rapid error logging if in a tight loop
                
    except Exception as e:
        logger.exception("Critical error initializing audio capture (PyAudio setup or stream open).")
        st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ–∑–∞—Ö–≤–∞—Ç–∞: {e}")
    finally:
        if stream:
            try:
                if not stream.is_stopped(): # type: ignore
                    stream.stop_stream()
                stream.close()
                logger.info("PyAudio stream stopped and closed.")
            except Exception as e:
                logger.error("Error stopping/closing audio stream.", exc_info=True)
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞: {e}")
        if p:
            try:
                p.terminate()
                logger.info("PyAudio terminated.")
            except Exception as e:
                logger.error("Error terminating PyAudio.", exc_info=True)
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ PyAudio: {e}")
        st.info("–ê—É–¥–∏–æ–∑–∞—Ö–≤–∞—Ç –∑–∞–≤–µ—Ä—à–µ–Ω.") # This message might be confusing if capture never started
        logger.info("Audio capture thread stopping.")


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
def multimodal_analysis_thread(integrator):
    logger.info("Multimodal analysis thread started.")
    try:
        while not stop_event.is_set():
            if integrator:
                current_time = time.time()
                # result = integrator.analyze_multimodal(current_time) # Result not currently used
                integrator.analyze_multimodal(current_time) 
            else:
                logger.warning("MultimodalIntegrator is None, skipping analysis.")
                # If integrator is critical, thread could stop. For now, it just waits.
            time.sleep(0.5)
    except Exception as e:
        logger.exception("Exception in multimodal_analysis_thread.")
        # Consider st.error if this thread's failure is critical to user experience
    finally:
        logger.info("Multimodal analysis thread stopping.")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
@st.cache_resource
def init_analyzers():
    logger.info("Initializing analyzers, models, and managers...")
    config = {}
    try:
        logger.debug("Loading configuration from config.yaml.")
        with open("config.yaml", "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        logger.info("config.yaml loaded successfully.")
    except FileNotFoundError:
        logger.error("config.yaml not found. Using default configurations.")
        st.error("–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ config.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω. –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
    except Exception as e:
        logger.exception("Failed to load or parse config.yaml.")
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (config.yaml): {e}. –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")

    audio_config = config.get("audio", {})
    whisper_model = audio_config.get("whisper_model", "tiny")
    whisper_language = audio_config.get("whisper_language", "ru")
    logger.info(f"Audio config: whisper_model='{whisper_model}', language='{whisper_language}'.")

    video_analyzer = None
    if cv2_available:
        logger.info("Attempting to initialize VideoAnalyzer...")
        try:
            video_analyzer = VideoAnalyzer()
            logger.info("VideoAnalyzer initialized successfully.")
        except Exception as e:
            logger.exception("Failed to initialize VideoAnalyzer.")
            st.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å VideoAnalyzer: {e}. –í–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            video_analyzer = None
    else:
        logger.warning("VideoAnalyzer will not be initialized as cv2 is unavailable.")
        pass # st.error for cv2 unavailability is already handled at import time

    audio_analyzer = None
    if pyaudio_available:
        logger.info("Attempting to initialize AudioAnalyzer...")
        try:
            audio_analyzer = AudioAnalyzer(model_size=whisper_model, language=whisper_language)
            logger.info("AudioAnalyzer initialized successfully.")
        except Exception as e:
            logger.exception("Failed to initialize AudioAnalyzer.")
            st.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AudioAnalyzer: {e}. –ê—É–¥–∏–æ–∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            audio_analyzer = None
    else:
        logger.warning("AudioAnalyzer will not be initialized as pyaudio is unavailable.")
        pass # st.error for pyaudio unavailability is already handled at import time
        
    integrator = None
    logger.info("Attempting to initialize MultimodalIntegrator...")
    try:
        integrator = MultimodalIntegrator(video_analyzer, audio_analyzer)
        logger.info("MultimodalIntegrator initialized successfully.")
    except Exception as e:
        logger.exception("Failed to initialize MultimodalIntegrator.")
        st.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å MultimodalIntegrator: {e}. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")
        integrator = None
    
    question_manager = None
    logger.info("Attempting to initialize QuestionManager...")
    try:
        data_dir = Path("data")
        if not data_dir.exists():
            logger.info(f"Data directory {data_dir} not found, creating it.")
            data_dir.mkdir(parents=True)
        
        questions_path = data_dir / "questions.csv"
        if not questions_path.exists():
            logger.info(f"Questions file {questions_path} not found, creating a default one.")
            import pandas as pd # Local import is fine here
            default_questions = pd.DataFrame({
                'id': range(1, 4),
                'text': [
                    "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ —Ä–∞–±–æ—Ç—ã –≤ –∫–æ–º–∞–Ω–¥–µ",
                    "–ö–∞–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º –ø—Ä–æ–µ–∫—Ç–µ?",
                    "–ö–∞–∫ –≤—ã —Ä–µ—à–∞–µ—Ç–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏?"
                ],
                'category': ['–æ–±—â–∏–µ', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ', '–ª–∏—á–Ω–æ—Å—Ç–Ω—ã–µ']
            })
            default_questions.to_csv(questions_path, index=False)
            logger.info(f"Default questions.csv created at {questions_path}.")
        
        question_manager = QuestionManager(str(questions_path))
        logger.info("QuestionManager initialized successfully.")
    except Exception as e:
        logger.exception("Failed to initialize QuestionManager.")
        st.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤: {e}. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        question_manager = None # Ensure it's None on failure
    
    logger.info("Finished initializing analyzers and question manager.")
    return video_analyzer, audio_analyzer, integrator, question_manager

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ —Å–µ—Å—Å–∏–∏
def start_session(video_analyzer, audio_analyzer, integrator):
    global stop_event, session_active
    logger.info("Start session called.")
    
    if stop_event.is_set():
        logger.info("Stop event was set, clearing it now for new session.")
        stop_event.clear()
    
    # –°–±—Ä–æ—Å –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    if video_analyzer:
        try:
            video_analyzer.reset_baseline()
            logger.info("VideoAnalyzer baseline reset.")
        except Exception as e:
            logger.exception("Error resetting VideoAnalyzer baseline.")
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.")
    if audio_analyzer:
        try:
            audio_analyzer.reset_baseline()
            logger.info("AudioAnalyzer baseline reset.")
        except Exception as e:
            logger.exception("Error resetting AudioAnalyzer baseline.")
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∞—É–¥–∏–æ–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.")
    if integrator:
        try:
            integrator.clear_history()
            logger.info("MultimodalIntegrator history cleared.")
        except Exception as e:
            logger.exception("Error clearing MultimodalIntegrator history.")
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.")
    
    # –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–æ–≤ –∑–∞—Ö–≤–∞—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞
    if cv2_available and video_analyzer:
        logger.info("Starting video_capture_thread.")
        threading.Thread(target=video_capture_thread, args=(video_analyzer, integrator), daemon=True).start()
    else:
        logger.warning("Video capture thread will not be started as video analysis is unavailable.")
        # st.warning already handled by init and main UI
        
    if pyaudio_available and audio_analyzer:
        logger.info("Starting audio_capture_thread.")
        threading.Thread(target=audio_capture_thread, args=(audio_analyzer, integrator), daemon=True).start()
    else:
        logger.warning("Audio capture thread will not be started as audio analysis is unavailable.")
        # st.warning already handled by init and main UI
        
    if integrator: 
        logger.info("Starting multimodal_analysis_thread.")
        threading.Thread(target=multimodal_analysis_thread, args=(integrator,), daemon=True).start()
    else:
        logger.warning("Multimodal analysis thread will not be started as integrator is unavailable.")

    session_active = True
    st.session_state.session_active = True
    logger.info("Session marked as active.")

# –§—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–µ—Å—Å–∏–∏
def stop_session():
    global stop_event, session_active
    logger.info("Stop session called.")
    stop_event.set()
    session_active = False
    st.session_state.session_active = False
    logger.info("Session marked as inactive and stop_event set.")

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
def main():
    logger.info("Streamlit application main() function started.")
    st.set_page_config(
        page_title="–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤",
        page_icon="üìä",
        layout="wide"
    )
    logger.debug("Streamlit page configured.")
    
    st.title("–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–æ–≤")
    logger.debug("Page title set.")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤
    video_analyzer, audio_analyzer, integrator, question_manager = init_analyzers()
    logger.info("Analyzers and managers initialization process completed in main().")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º
    with st.sidebar:
        st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏–µ–π
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –≤–æ–æ–±—â–µ –Ω–∞—á–∞—Ç—å —Å–µ—Å—Å–∏—é
        # –î–æ–±–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ integrator
        can_start_session = ((video_analyzer is not None and cv2_available) or \
                            (audio_analyzer is not None and pyaudio_available)) and \
                            integrator is not None

        col1, col2 = st.columns(2)
        with col1:
            if st.button("–ù–∞—á–∞—Ç—å —Å–µ—Å—Å–∏—é", key="start_session",
                        disabled=st.session_state.get('session_active', False) or not can_start_session):
                if can_start_session:
                    start_session(video_analyzer, audio_analyzer, integrator)
                else:
                    # –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                    error_messages = []
                    if not cv2_available:
                        error_messages.append("OpenCV (cv2) –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω.")
                    logger.debug("Start session condition: OpenCV not available.")
                    elif video_analyzer is None:
                        error_messages.append("VideoAnalyzer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
                        logger.debug("Start session condition: VideoAnalyzer is None.")
                    if not pyaudio_available:
                        error_messages.append("PyAudio –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω.")
                        logger.debug("Start session condition: PyAudio not available.")
                    elif audio_analyzer is None:
                        error_messages.append("AudioAnalyzer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
                        logger.debug("Start session condition: AudioAnalyzer is None.")
                    if integrator is None:
                        error_messages.append("MultimodalIntegrator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
                        logger.debug("Start session condition: MultimodalIntegrator is None.")
                    
                    err_msg_for_user = f"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å–µ—Å—Å–∏—é: {', '.join(error_messages)}"
                    logger.error(f"Cannot start session: {err_msg_for_user}")
                    st.error(err_msg_for_user)
        
        with col2:
            if st.button("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Å–µ—Å—Å–∏—é", key="stop_session",
                        disabled=not st.session_state.get('session_active', False)):
                logger.info("Stop session button clicked.")
                stop_session()

        if not can_start_session:
             logger.warning("Session start is not possible due to component initialization issues or missing dependencies. UI warning displayed.")
             st.warning("–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.")
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å, –¥–∞–∂–µ –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å
        if question_manager is not None:
            logger.debug("Question manager available, setting up question controls.")
            if st.button("–°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å", key="next_question",
                        disabled=not st.session_state.get('session_active', False)): 
                logger.info("Next question button clicked.")
                question = question_manager.next_question()
                if question is None:
                    logger.info("No more questions available. Stopping session.")
                    st.warning("–í–æ–ø—Ä–æ—Å—ã –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å. –°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
                    stop_session() 
                else:
                    logger.info(f"Displaying new question ID: {question.get('id', 'N/A')}")
            
            st.header("–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å")
            current_question = question_manager.get_current_question()
            if current_question is not None:
                logger.debug(f"Displaying question: {current_question['text']}")
                st.markdown(f"**{current_question['text']}**")
                current, total, percent = question_manager.get_progress()
                st.progress(percent)
                st.text(f"–í–æ–ø—Ä–æ—Å {current} –∏–∑ {total}")
            elif st.session_state.get('session_active', False): 
                 st.info("–ù–∞–∂–º–∏—Ç–µ '–°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å', —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∏–ª–∏ –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è.")
            else: 
                 st.info("–ù–∞—á–Ω–∏—Ç–µ —Å–µ—Å—Å–∏—é, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –≤–æ–ø—Ä–æ—Å—ã.")
        else:
            logger.error("Question manager is None. Question functionality unavailable in UI.")
            st.error("–ú–µ–Ω–µ–¥–∂–µ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
    logger.debug("Sidebar UI setup complete.")
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å —Å –∞–Ω–∞–ª–∏–∑–æ–º
    col1, col2 = st.columns([2, 1])
    
    video_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    with col1:
        st.header("–í–∏–¥–µ–æ –∞–Ω–∞–ª–∏–∑")
        if cv2_available and video_analyzer:
            video_placeholder = st.empty()
        elif cv2_available and video_analyzer is None: # cv2 –µ—Å—Ç—å, –Ω–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è
            st.error("VideoAnalyzer –Ω–µ —Å–º–æ–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è. –í–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        elif not cv2_available: # cv2 –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
            st.warning("–í–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: OpenCV (cv2) –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else: # –û–±—â–∏–π —Å–ª—É—á–∞–π
            st.warning("–í–∏–¥–µ–æ–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
            
    speech_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    indicators_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    with col2:
        st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        
        st.subheader("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è —Ä–µ—á—å")
        if pyaudio_available and audio_analyzer:
            speech_placeholder = st.empty()
        elif pyaudio_available and audio_analyzer is None:
            st.error("AudioAnalyzer –Ω–µ —Å–º–æ–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.")
        elif not pyaudio_available:
            st.warning("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: PyAudio –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else:
            st.warning("–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.")

        st.subheader("–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç —á–∞—Å—Ç–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å, –µ—Å–ª–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –µ—Å—Ç—å, –¥–∞–∂–µ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ
        if integrator:
            indicators_placeholder = st.empty()
            if video_analyzer is None and cv2_available:
                 st.warning("–ß–∞—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –≤–∏–¥–µ–æ) –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ VideoAnalyzer.")
            if audio_analyzer is None and pyaudio_available:
                 st.warning("–ß–∞—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∞—É–¥–∏–æ) –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ AudioAnalyzer.")
        else:
            st.error("–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: MultimodalIntegrator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            
    # –†–∞–∑–¥–µ–ª —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    st.header("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
    chart_col1, chart_col2 = st.columns(2)
    
    voice_chart_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    with chart_col1:
        st.subheader("–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≥–æ–ª–æ—Å–∞")
        if pyaudio_available and audio_analyzer:
            voice_chart_placeholder = st.empty()
        elif pyaudio_available and audio_analyzer is None:
            st.error("AudioAnalyzer –Ω–µ —Å–º–æ–≥ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è. –ì—Ä–∞—Ñ–∏–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        elif not pyaudio_available:
            st.warning("–ì—Ä–∞—Ñ–∏–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: PyAudio –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else:
            st.warning("–ì—Ä–∞—Ñ–∏–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")

    timeline_chart_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    with chart_col2:
        st.subheader("–í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤")
        if integrator:
            timeline_chart_placeholder = st.empty()
        else:
            st.error("–í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: MultimodalIntegrator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏
    summary_placeholder = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
    st.header("–°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    if integrator:
        summary_placeholder = st.empty()
    else:
        st.error("–°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: MultimodalIntegrator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ UI
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ update_ui –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã None,
    # —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–æ–≥–∏–∫—É –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ–± –æ—à–∏–±–∫–∞—Ö –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö
    # –∏–ª–∏ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥—Ä—É–≥–∏–µ —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ Streamlit.
    update_ui(
        video_analyzer, audio_analyzer, integrator,
        video_placeholder, speech_placeholder, indicators_placeholder,
        voice_chart_placeholder, timeline_chart_placeholder, summary_placeholder
    )

def update_ui(
    video_analyzer, audio_analyzer, integrator,
    video_placeholder, speech_placeholder, indicators_placeholder,
    voice_chart_placeholder, timeline_chart_placeholder, summary_placeholder
):
    """–§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è UI. –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É—Å—Ç–æ–π—á–∏–≤–∞ –∫ None –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º."""
    
    pitch_values = []
    intensity_values = []
    timestamps = []
    last_speech_text = ""
    summary_counter = 0  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π
    
    while True:
        try:
            # –í—ã—Ö–æ–¥ –∏–∑ —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ —Å–µ—Å—Å–∏—è –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞
            if not st.session_state.get('session_active', False):
                time.sleep(0.1) # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å CPU –≤ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
                continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ —Å–µ—Å—Å–∏—è –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞
                
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ
            if cv2_available and video_analyzer and video_placeholder and not frame_queue.empty():
                try:
                    frame = frame_queue.get_nowait() # –ò—Å–ø–æ–ª—å–∑—É–µ–º get_nowait –¥–ª—è –Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–µ–≥–æ —á—Ç–µ–Ω–∏—è
                    video_placeholder.image(frame, channels="BGR", use_column_width=True)
                except queue.Empty:
                    pass # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –Ω–∏—á–µ–≥–æ —Å—Ç—Ä–∞—à–Ω–æ–≥–æ
            
            audio_results = None 
            if pyaudio_available and audio_analyzer:
                try:
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ get_latest_results() –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—â–∏–π –∏–ª–∏ –±—ã—Å—Ç—Ä–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç
                    audio_results = audio_analyzer.get_latest_results() 
                    if audio_results and 'text' in audio_results and audio_results['text']:
                        last_speech_text = audio_results['text']
                        if speech_placeholder:
                            speech_placeholder.markdown(f"*{last_speech_text}*")
                        
                        if 'pitch' in audio_results and 'intensity' in audio_results:
                            pitch_values.append(audio_results['pitch'])
                            intensity_values.append(audio_results['intensity'])
                            timestamps.append(time.time())
                            max_points = 50
                            if len(pitch_values) > max_points:
                                pitch_values = pitch_values[-max_points:]
                                intensity_values = intensity_values[-max_points:]
                                timestamps = timestamps[-max_points:]
                except Exception as e:
                    # st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}") # –ú–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π
                    pass # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º–∞

            distortions = {}
            if cv2_available and video_analyzer:
                try:
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ get_distortions() –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—â–∏–π
                    distortions = video_analyzer.get_distortions()
                except Exception as e:
                    # st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤–∏–¥–µ–æ –∏—Å–∫–∞–∂–µ–Ω–∏–π: {e}")
                    pass

            if indicators_placeholder: 
                indicators_text = []
                if cv2_available and video_analyzer and distortions:
                    for region, is_distorted in distortions.items():
                        status = "üî¥" if is_distorted else "üü¢"
                        indicators_text.append(f"{status} {region}")
                
                if pyaudio_available and audio_analyzer and audio_results and 'voice_change' in audio_results:
                    voice_status = "üî¥" if audio_results['voice_change'] else "üü¢"
                    indicators_text.append(f"{voice_status} –≥–æ–ª–æ—Å")
                
                if not indicators_text and (video_analyzer or audio_analyzer): # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä, –Ω–æ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
                    indicators_text.append("–î–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è.")
                elif not video_analyzer and not audio_analyzer : # –ï—Å–ª–∏ –æ–±–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã
                     indicators_text.append("–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã).")


                indicators_placeholder.markdown("<br>".join(indicators_text), unsafe_allow_html=True)
            
            if pyaudio_available and audio_analyzer and voice_chart_placeholder and pitch_values and intensity_values:
                try:
                    voice_fig = plot_voice_characteristics(pitch_values, intensity_values)
                    if voice_fig:
                        voice_chart_placeholder.pyplot(voice_fig)
                except Exception as e:
                    # st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –≥–æ–ª–æ—Å–∞: {e}")
                    pass
            
            if integrator and timeline_chart_placeholder and summary_placeholder:
                try:
                    recent_results = integrator.get_recent_results()
                    if recent_results:
                        if timeline_chart_placeholder:
                            timeline_fig = plot_multimodal_timeline(recent_results)
                            if timeline_fig:
                                timeline_chart_placeholder.pyplot(timeline_fig)
                        
                        if summary_placeholder:
                            summary_text = create_distortion_summary(recent_results)
                            summary_counter += 1
                            summary_placeholder.text_area("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:", summary_text, height=200, key=f"summary_{summary_counter}")
                except Exception as e:
                    # st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∫–∞–ª—ã –∏–ª–∏ —Å–≤–æ–¥–∫–∏: {e}")
                    pass
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ CPU.
            # –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã —ç—Ç–∞ –∑–∞–¥–µ—Ä–∂–∫–∞ –±—ã–ª–∞ –∑–¥–µ—Å—å, —á—Ç–æ–±—ã UI –æ—Å—Ç–∞–≤–∞–ª—Å—è –æ—Ç–∑—ã–≤—á–∏–≤—ã–º.
            time.sleep(0.1)
            
        except Exception as e:
            logger.exception("Unhandled error in update_ui loop.") # Logs full traceback
            st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞: {e}")
            time.sleep(1) # Prevent rapid error logging if in a tight loop

if __name__ == "__main__":
    logger.info("Application script execution started (__main__ block).")
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏
    if 'session_active' not in st.session_state:
        logger.debug("Initializing 'session_active' in st.session_state to False.")
        st.session_state.session_active = False
    
    main()
    logger.info("Application script execution finished (__main__ block).")